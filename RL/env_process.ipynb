{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 这一节使用wrapper对gym环境进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先引入下相关包\r\n",
    "import gym_super_mario_bros\r\n",
    "from gym.spaces import Box\r\n",
    "from gym import Wrapper\r\n",
    "from nes_py.wrappers import JoypadSpace#BinarySpaceToDiscreteSpaceEnv\r\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT, RIGHT_ONLY\r\n",
    "import cv2\r\n",
    "import numpy as np\r\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGB图像转灰度图\r\n",
    "#借助cv2即（opencv）包快速转换COLOR_RGB2GRAY\r\n",
    "def process_frame(frame):\r\n",
    "    if frame is not None:\r\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY) #图像转换\r\n",
    "        frame = cv2.resize(frame, (84, 84))[None, :, :] / 255. #裁剪合适大小，并归一化\r\n",
    "        return frame\r\n",
    "    else:\r\n",
    "        return np.zeros((1, 84, 84))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#写一个继承Wrapper的包装类，一定注意在构造方法中调用父类的构造函数\r\n",
    "#1.包装类copy了原环境的以下信息,在新的类初始化时要进行相应的修改,虽然这些量\r\n",
    "#  在实现新的环境逻辑时不一定用得到;此外在包装类初始化时还要定义一些别的要\r\n",
    "#  使用的变量\r\n",
    "'''self.env = env\r\n",
    "   self.action_space = self.env.action_space\r\n",
    "   self.observation_space = self.env.observation_space\r\n",
    "   self.reward_range = self.env.reward_range\r\n",
    "   self.metadata = self.env.metadata'''\r\n",
    "#2.同时新的环境逻辑通过重写step和reset方法实现,只能重写step和reset\r\n",
    "\r\n",
    "class CustomReward(Wrapper):\r\n",
    "  '''这个类的作用\r\n",
    "  1.处理状态空间,将RGB转为灰度,并将图像裁剪为84x84\r\n",
    "  2.设定新的奖励函数\r\n",
    "  这里我们做了几个小优化如下：\r\n",
    "      1).reward += (info[\"score\"] - self.curr_score) / 40.\r\n",
    "      原来的reward仅包含了对“离终点更近”的奖励和“时间消耗”、”死掉“的惩罚\r\n",
    "      为了让游戏更好玩，我们添加了info[\"score\"]，包含了对获得技能、金币的\r\n",
    "      奖励，但不是重点，为了不影响整体要通关的属性，弱化他\r\n",
    "      2).我们对回合结束时到达终点和未达到的奖励和惩罚进行放大，激励agent\r\n",
    "      更快速的到达终点\r\n",
    "      if done:\r\n",
    "                  if info[\"flag_get\"]:\r\n",
    "                      reward += 50\r\n",
    "                  else:\r\n",
    "                      reward -= 50\r\n",
    "      \r\n",
    "      3.这里仅仅是对reward修改的一些示例，后面自己在实战时可以自己根据实际\r\n",
    "      情况进行定义，比如当agent有时陷入一个错误的路线卡住时，可以添加一个缓\r\n",
    "      冲区让agent学会后退等\r\n",
    "  '''\r\n",
    "\r\n",
    "  def __init__(self, env=None):\r\n",
    "      super().__init__(env)\r\n",
    "      self.observation_space= Box(low=0,high=255,shape=(1,84,84))\r\n",
    "      self.curr_score = 0\r\n",
    "\r\n",
    "  # 重写step方法以处理状态空间并规定新的奖励函数\r\n",
    "  def step(self,action):\r\n",
    "      # 走一步,拿到原有的奖励\r\n",
    "      state,reward,done,info=self.env.step(action)\r\n",
    "      state=process_frame(state)\r\n",
    "      reward += (info[\"score\"]-self.curr_score)/40.\r\n",
    "      self.curr_score = info[\"score\"]\r\n",
    "      if done:\r\n",
    "          if info[\"flag_get\"]:\r\n",
    "              reward += 50\r\n",
    "          else:\r\n",
    "              reward -= 50\r\n",
    "      return state, reward / 10., done, info\r\n",
    "  #reset需要初始化一些自定义变量并返回一个初始状态\r\n",
    "  def reset(self):\r\n",
    "    self.curr_score = 0\r\n",
    "    return process_frame(self.env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 在学习时并不需要所有帧,我们可以连续4帧给相同的输入,并将结果合并为一帧\r\n",
    "class CustomSkipFrame(Wrapper):\r\n",
    "    def __init__(self, env,skip=4) -> None:\r\n",
    "        super().__init__(env)\r\n",
    "        self.observation_space = Box(low=0, high=255, shape=(4, 84, 84))\r\n",
    "        self.skip = skip\r\n",
    "\r\n",
    "    def step(self, action):\r\n",
    "        total_reward = 0\r\n",
    "        states = []\r\n",
    "        state, reward, done, info = self.env.step(action)\r\n",
    "        for i in range(self.skip):\r\n",
    "            if not done:\r\n",
    "                state, reward, done, info = self.env.step(action)\r\n",
    "                total_reward += reward\r\n",
    "                states.append(state)\r\n",
    "            else:\r\n",
    "                states.append(state)\r\n",
    "        states = np.concatenate(states, 0)[None, :, :, :]\r\n",
    "        return states.astype(np.float32), reward, done, info  \r\n",
    "\r\n",
    "    def reset(self):\r\n",
    "        state = self.env.reset()\r\n",
    "        states = np.concatenate([state for _ in range(self.skip)], 0)[None, :, :, :]\r\n",
    "        return states.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#至此，我们完成了超级玛丽环境的自定义，封装如下：\r\n",
    "def create_train_env(world, stage, action_type, output_path=None):\r\n",
    "    env = gym_super_mario_bros.make(\"SuperMarioBros-{}-{}-v0\".format(world, stage))\r\n",
    "    if action_type == \"right\":\r\n",
    "        actions = RIGHT_ONLY\r\n",
    "    elif action_type == \"simple\":\r\n",
    "        actions = SIMPLE_MOVEMENT\r\n",
    "    else:\r\n",
    "        actions = COMPLEX_MOVEMENT\r\n",
    "    env = JoypadSpace(env, actions)\r\n",
    "    env = CustomReward(env)\r\n",
    "    env = CustomSkipFrame(env)\r\n",
    "    return env, env.observation_space.shape[0], len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<CustomSkipFrame<CustomReward<JoypadSpace<TimeLimit<SuperMarioBrosEnv<SuperMarioBros-1-1-v0>>>>>>, 4, 7)\n"
     ]
    }
   ],
   "source": [
    "#测试一下\r\n",
    "custom_env = create_train_env(1,1,'simple')\r\n",
    "print(custom_env)\r\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b4b4feff2f24a0f0a34464dbe537a36fda679851528fb8735cb41fa49dffb2d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}